#### 基本存储需求
一般业务sql代码量比较大,做sql解析的时候, 参与运算的字符串比较大.

考虑到Redis 当单个字符串超过1M的时候性能会下降. 所以需要将长字符串压缩到1M以下存储.
对一般SQL长度进行最悲观预估, 15 行Sql 共计450字符, 预测支持1000行 30000字符共计
60000B<65536B=64KB<1MB, 不会影响Redis存储的性能.


考虑到Mysql存储大字符串需要使用TEXT类型, 如果数据过长可能会导致一条记录跨数据块. 这样的
检索速度就变慢了, 所以需要将字符串数据进行压缩.

下面试一下常用的压缩算法性能比较:
各类压缩算法的性能对比:

| Format  | Size Before(byte) | Size After(byte) | Compress Expend(ms) | UnCompress Expend(ms) | MAX CPU(%) |
| ------- | ----------------- | ---------------- | ------------------- | --------------------- | ---------- |
| bzip2   | 35984             | 8677             | 11591               | 2362                  | 29.5       |
| gzip    | 35984             | 8804             | 2179                | 389                   | 26.5       |
| deflate | 35984             | 9704             | 680                 | 344                   | 20.5       |
| lzo     | 35984             | 13069            | 581                 | 230                   | 22         |
| lz4     | 35984             | 16355            | 327                 | 147                   | 12.6       |
| snappy  | 35984             | 13602            | 424                 | 88                    | 11         |

首先需要对业务常用Sql的代码长度进行调研, 再确定压缩比, 选择合适的字符串压缩算法.

这里由于Sql解析既需要工作中离线情况下,也需要工作再实时状态下. 可以根据不同的需要选择压缩算法.
离线Sql解析很显然使用Gzip压缩算法是合适的, 64KB数据最后会压缩之后大概17KB.
而实时sql解析对压缩时间有要求, 则使用lz4算法比较合适, 此外压缩完数据比较大,可以考虑存储到Redis中. 并配合AOF进行容灾处理.

按照上述悲观数据预估最大需要存储64KB, 在mysql中持久化需要17KB的数据, 这些数据存储在mysql中是不合适的.
这些压缩后端sql文本数据,首先会过内存解析血缘关系, 并且使用MD5摘要算法快速对sql文档进行唯一标识, 使用这个标识符将血缘关系存储到mysql中.

由于文档数据库MongoDB中单条记录最大16M,真好满足sql文本存储需求, 所以可以考虑将文本数据存储到MongoDB中.

考虑对接后端服用功能, 需要根据标识符同时从两个数据库提取文本数据和血缘数据

#### Mongo文档设计


